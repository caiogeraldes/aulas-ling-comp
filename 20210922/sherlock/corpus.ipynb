{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LC - Pós - Corpus 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJniIcJpHLc4"
      },
      "source": [
        "# Leitura e Gravação de arquivos de texto\n",
        "\n",
        "Para ler ou gravar arquivos textos, existe a função open(). \n",
        "\n",
        "Para gravação, passe como parâmetros as seguintes strings:\n",
        "\n",
        "- O nome do arquivo (com a extensão .txt) \n",
        "- 'w' (de \"Write\")\n",
        "\n",
        "Para leitura, o segundo parâmetro deve ser 'r' (\"Read).\n",
        "\n",
        "Ao final das operações de leitura ou gravação, use o método close() sobre o objeto (arquivo) que você criou com open()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOoLSD6jG4Nu"
      },
      "source": [
        "### GRAVAÇÃO\n",
        "\n",
        "arq = open('Teste.txt', 'w')  # Note o parâmetro 'w'\n",
        "\n",
        "# Apresentando a string multilinhas, delimitada por '''\n",
        "texto = '''\n",
        "Eis aqui a primeira sentença.\n",
        "Esta é a segunda sentença.\n",
        "E esta é a terceira!\n",
        "'''\n",
        "\n",
        "arq.write(texto)  # Escreve uma string no arquivo\n",
        "\n",
        "arq.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NqKpZyZ4K6Te",
        "outputId": "89e397d1-cc1f-4348-a1e3-f9942b3fc564"
      },
      "source": [
        "### LEITURA\n",
        "\n",
        "arq = open('Teste.txt', 'r')  # Note o parâmetro 'r'\n",
        "\n",
        "corpus = arq.read()  # Lê o conteúdo do arquivo de uma só vez\n",
        "\n",
        "arq.close()  # Não deixe de fechar o arquivo assim que você concluir a operação\n",
        "\n",
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nEis aqui a primeira sentença.\\nEsta é a segunda sentença.\\nE esta é a terceira!\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw7qtbSdhIOO"
      },
      "source": [
        "# Tokenização\n",
        "\n",
        "É o nome dado à divisão do texto em unidades mínimas, que podem ser sentenças, palavras ou caracteres, a depender do interesse da análise. Geralmente, os tokens são palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWfCs15AhFUq",
        "outputId": "b9cfd9f9-91d7-45c6-c068-52310fc9e113"
      },
      "source": [
        "# Tokenização em sentenças\n",
        "\n",
        "corpus.split('\\n')  # Aqui estamos aproveitando o caracter especial de nova linha como delimitador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'Eis aqui a primeira sentença.',\n",
              " 'Esta é a segunda sentença.',\n",
              " 'E esta é a terceira!',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB8bp0BekeHs"
     },
      "source": [
        "# Exercício\n",
        "\n",
        "1. Crie sua própria string usando o início do texto de estreia de Sherlock Holmes, *Um Estudo em Vermelho* (\"A Study in Scarlet\", de 1887):\n",
        "\n",
        "---\n",
        "In the year 1878 I took my degree of Doctor of Medicine of the University of London, and proceeded to Netley to go through the course prescribed for surgeons in the army. Having completed my studies there, I was duly attached to the Fifth Northumberland Fusiliers as Assistant Surgeon. The regiment was stationed in India at the time, and before I could join it, the second Afghan war had broken out. On landing at Bombay, I learned that my corps had advanced through the passes, and was already deep in the enemy’s country. I followed, however, with many other officers who were in the same situation as myself, and succeeded in reaching Candahar in safety, where I found my regiment, and at once entered upon my new duties.\n",
        "\n",
        "The campaign brought honours and promotion to many, but for me it had nothing but misfortune and disaster. I was removed from my brigade and attached to the Berkshires, with whom I served at the fatal battle of Maiwand. There I was struck on the shoulder by a Jezail bullet, which shattered the bone and grazed the subclavian artery. I should have fallen into the hands of the murderous Ghazis had it not been for the devotion and courage shown by Murray, my orderly, who threw me across a pack-horse, and succeeded in bringing me safely to the British lines. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "2. Grave um arquivo TXT contendo o texto.\n",
        "\n",
        "1. Leia o arquivo e atribua o conteúdo a uma string.\n",
        "\n",
        "1. Tokenize a string em sentenças e atribua o resultado a uma variável \"sents\".\n",
        "\n",
        "1. Tokenize a string em palavras e atribua o resultado a uma variável \"palavras\".\n",
        "\n",
        "1. Tokenize a string em caracteres e atribua o resultado a uma variável \"caracteres\".\n",
        "\n",
        "1. Quantas são as sentenças?\n",
        "\n",
        "1. Quantas são as palavras?\n",
        "\n",
        "1. Quantos são os caracteres?\n",
        "\n",
        "1. Qual é o vocubulário do texto?\n",
        "\n",
        "1. Qual o tamanho do vocabulário?\n",
        "\n",
        "1. Crie uma lista de contagens de ocorrências das palavras.\n",
        "\n",
        "1. Quais são as 10 palavras mais frequentes e suas respectivas contagens?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89wQ8B0rsKt4"
      },
      "source": [
        "# Tarefa: Seu primeiro romance\n",
        "\n",
        "No Moodle, você encontrará o arquivo TXT do romance \"O Guarani\", de José de Alencar (1857). Com base nesse texto, repita o exercício anterior do item 3 em diante."
      ]
    }
  ]
} 
